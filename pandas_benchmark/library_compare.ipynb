{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc660916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 18:02:44,116\tINFO services.py:1456 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.9.13', ray_version='1.12.1', ray_commit='4863e33856b54ccf8add5cbe75e41558850a1b75', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:64965', 'raylet_socket_name': 'tcp://127.0.0.1:64867', 'webui_url': '127.0.0.1:8265', 'session_dir': 'C:\\\\Users\\\\jay\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2023-03-09_18-02-42_164448_18244', 'metrics_export_port': 65435, 'gcs_address': '127.0.0.1:64835', 'address': '127.0.0.1:64835', 'node_id': '2e018927715cd6c95a800a3b73cd308aa46552201c3842ce72f219dc'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "#import pandas as pd\n",
    "import modin.pandas as mpd\n",
    "import ray\n",
    "ignore_reinit_error=True\n",
    "ray.init()\n",
    "#import polars as pl\n",
    "#from datatable import dt, f, by, g, join, sort, update, ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174b89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = '10_million_1.csv'\n",
    "file_2 = '10_million_2.csv'\n",
    "num_ran = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace5dc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_name = 'pandas'\n",
    "stats = []\n",
    "\n",
    "for i in range (num_ran):\n",
    "    stats_inner = {}\n",
    "    start = time.time()\n",
    "    df_1 = pd.read_csv(file_1,  engine=\"pyarrow\", use_nullable_dtypes=True, index_col = 0)\n",
    "    print(f'loading csv with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['loading_1'] = (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    df_2 = pd.read_csv(file_2, engine=\"pyarrow\", use_nullable_dtypes=True, index_col = 0)\n",
    "    print(f'loading csv with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['loading_2'] = (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    df_1.merge(df_2, on = 'unique_id_text' )\n",
    "    print(f'merge csv on unique_id_text with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['merging'] = (time.time() - start)\n",
    "\n",
    "    ## out of memory\n",
    "    start=time.time()\n",
    "    pd.concat([df_1, df_2])\n",
    "    print(f'concat csv with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['concat'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1.groupby('text_id').sum()\n",
    "    print(f'groupby and sum by text_id with {lib_name} took: {time.time() - start} seconds ')\n",
    "    stats_inner['groupby'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1['new_col'] = df_1['0'].apply(round)\n",
    "    print(f'apply round method with {lib_name} took {time.time() - start} seconds.')\n",
    "    stats_inner['apply'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1.loc[df_1['text_id'] == '9999_ID']\n",
    "    print(f'.loc filter took {time.time() - start} seconds.')\n",
    "    stats_inner['filtering'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1.loc[df_1['text_id'] == '9999_ID', 'text_id'] = 'found it'\n",
    "    print(f'.loc filter and update value took {time.time() - start} seconds.')\n",
    "    stats_inner['filtering & updating'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1['0_new'] = df_1['0'] * 2 + 1\n",
    "    print(f'simple calculation took {time.time() - start} seconds.')\n",
    "    stats_inner['column calculation'] = (time.time() - start)\n",
    "    \n",
    "    stats.append(stats_inner)\n",
    "    \n",
    "print([k for k in sorted(stats[0].keys())])\n",
    "pandas_stats = [round((stats[0][k] + stats[1][k])/2,5) for k in sorted(stats[0].keys())]\n",
    "print(pandas_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(file_1,  engine=\"pyarrow\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98866c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['unique_id_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69129e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a442557",
   "metadata": {},
   "source": [
    "# modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331aa5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading csv with modin took: 4.665002107620239 seconds\n",
      "loading csv with modin took: 4.518391132354736 seconds\n",
      "merge csv on unique_id_text with modin took: 73.4125304222107 seconds\n",
      "concat csv with modin took: 0.0729975700378418 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_apply_func pid=20676)\u001b[0m E0309 18:07:42.921000000 39528 src/core/ext/transport/chttp2/transport/chttp2_transport.cc:1103] Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_list_of_funcs pid=20928)\u001b[0m E0309 18:07:43.019000000  8232 src/core/ext/transport/chttp2/transport/chttp2_transport.cc:1103] Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=38580)\u001b[0m E0309 18:07:43.126000000 13564 src/core/ext/transport/chttp2/transport/chttp2_transport.cc:1103] Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=30892)\u001b[0m E0309 18:07:43.258000000  9084 src/core/ext/transport/chttp2/transport/chttp2_transport.cc:1103] Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_list_of_funcs pid=25856)\u001b[0m E0309 18:07:43.345000000 23636 src/core/ext/transport/chttp2/transport/chttp2_transport.cc:1103] Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2528)\u001b[0m E0309 18:07:43.354000000 18872 src/core/ext/transport/chttp2/transport/chttp2_transport.cc:1103] Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby and sum by text_id with modin took: 3.26353120803833 seconds \n",
      "apply round method with modin took 0.9840505123138428 seconds.\n",
      ".loc filter took 0.6788806915283203 seconds.\n",
      ".loc filter and update value took 1.7393150329589844 seconds.\n",
      "simple calculation took 0.8209986686706543 seconds.\n",
      "loading csv with modin took: 7.100838899612427 seconds\n",
      "loading csv with modin took: 6.691199541091919 seconds\n",
      "merge csv on unique_id_text with modin took: 49.1641526222229 seconds\n",
      "concat csv with modin took: 0.04704713821411133 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_apply_func pid=34984)\u001b[0m E0309 18:08:53.433000000 34404 src/core/ext/transport/chttp2/transport/chttp2_transport.cc:1103] Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_list_of_funcs pid=25008)\u001b[0m E0309 18:08:53.569000000  8688 src/core/ext/transport/chttp2/transport/chttp2_transport.cc:1103] Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby and sum by text_id with modin took: 3.1725761890411377 seconds \n",
      "apply round method with modin took 0.9880001544952393 seconds.\n",
      ".loc filter took 0.6719996929168701 seconds.\n",
      ".loc filter and update value took 1.5485119819641113 seconds.\n",
      "simple calculation took 0.8470005989074707 seconds.\n",
      "['apply', 'column calculation', 'concat', 'filtering', 'filtering & updating', 'groupby', 'loading_1', 'loading_2', 'merging']\n",
      "[0.98652, 0.834, 0.06002, 0.67544, 1.64391, 3.21805, 5.88342, 5.6048, 61.29134]\n"
     ]
    }
   ],
   "source": [
    "lib_name = 'modin'\n",
    "\n",
    "stats = []\n",
    "\n",
    "for i in range (num_ran):\n",
    "    stats_inner = {}\n",
    "    start = time.time()\n",
    "    df_1 = mpd.read_csv(file_1,  index_col = 0)\n",
    "    print(f'loading csv with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['loading_1'] = (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    df_2 = mpd.read_csv(file_2,  index_col = 0)\n",
    "    print(f'loading csv with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['loading_2'] = (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    df_1.merge(df_2, on = 'unique_id_text' )\n",
    "    print(f'merge csv on unique_id_text with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['merging'] = (time.time() - start)\n",
    "\n",
    "    ## out of memory\n",
    "    start=time.time()\n",
    "    mpd.concat([df_1, df_2])\n",
    "    print(f'concat csv with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['concat'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1.groupby('text_id').sum()\n",
    "    print(f'groupby and sum by text_id with {lib_name} took: {time.time() - start} seconds ')\n",
    "    stats_inner['groupby'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1['new_col'] = df_1['0'].apply(round)\n",
    "    print(f'apply round method with {lib_name} took {time.time() - start} seconds.')\n",
    "    stats_inner['apply'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1.loc[df_1['text_id'] == '9999_ID']\n",
    "    print(f'.loc filter took {time.time() - start} seconds.')\n",
    "    stats_inner['filtering'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1.loc[df_1['text_id'] == '9999_ID', 'text_id'] = 'found it'\n",
    "    print(f'.loc filter and update value took {time.time() - start} seconds.')\n",
    "    stats_inner['filtering & updating'] = (time.time() - start)\n",
    "    \n",
    "    start=time.time()\n",
    "    df_1['0_new'] = df_1['0'] * 2 + 1\n",
    "    print(f'simple calculation took {time.time() - start} seconds.')\n",
    "    stats_inner['column calculation'] = (time.time() - start)\n",
    "    \n",
    "    stats.append(stats_inner)\n",
    "    \n",
    "print([k for k in sorted(stats[0].keys())])\n",
    "modin_stats = [round((stats[0][k] + stats[1][k])/2,5) for k in sorted(stats[0].keys())]\n",
    "print(modin_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2aa00f",
   "metadata": {},
   "source": [
    "# polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c0cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_name = 'polars'\n",
    "stats = []\n",
    "\n",
    "for i in range(num_ran):\n",
    "    stats_inner = {}\n",
    "    start = time.time()\n",
    "    df_1 = pl.read_csv(file_1)\n",
    "    print(f'loading csv with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['loading_1'] = (time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    df_2 = pl.read_csv(file_2)\n",
    "    print(f'loading csv with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['loading_2'] = (time.time() - start)\n",
    "\n",
    "    start=time.time()\n",
    "    pl.concat([df_1, df_2])\n",
    "    print(f'concat (append) csv with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['concat'] = (time.time() - start)\n",
    "\n",
    "    start=time.time()\n",
    "    df_1.join(df_2, on = 'unique_id_text')\n",
    "    print(f'join (merge) csv with {lib_name} took: {time.time() - start} seconds')\n",
    "    stats_inner['merging'] = (time.time() - start)\n",
    "\n",
    "    start=time.time()\n",
    "    df_1.groupby('text_id').sum()\n",
    "    print(f'groupby and sum by text_id with {lib_name} took: {time.time() - start} seconds ')\n",
    "    stats_inner['groupby'] = (time.time() - start)\n",
    "\n",
    "    start=time.time()\n",
    "    df_1['new_col'] = df_1['0'].apply(round)\n",
    "    print(f'apply round method with {lib_name} took {time.time() - start} seconds.')\n",
    "    stats_inner['apply'] = (time.time() - start)\n",
    "\n",
    "    start=time.time()\n",
    "    df_1[df_1['text_id'] == '9999_ID']\n",
    "    print(f'filter took {time.time() - start} seconds.')\n",
    "    stats_inner['filtering'] = (time.time() - start)\n",
    "\n",
    "    start=time.time()\n",
    "    df_1[df_1['text_id'] == '9999_ID', 'text_id'] = 'found it'\n",
    "    print(f'filter and update value took {time.time() - start} seconds.')\n",
    "    stats_inner['filtering & updating'] = (time.time() - start)\n",
    "\n",
    "    start=time.time()\n",
    "    df_1['0_2'] = df_1['0'] *2 + 1\n",
    "    print(f'simple column calculation with {lib_name} took {time.time() - start} seconds.')\n",
    "    stats_inner['column calculation'] = (time.time() - start)\n",
    "    \n",
    "    stats.append(stats_inner)\n",
    "\n",
    "print([k for k in sorted(stats[0].keys())])\n",
    "polars_stats = [round((stats[0][k] + stats[1][k])/2,5) for k in sorted(stats[0].keys())]\n",
    "print(polars_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6addf795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pl.read_csv(file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504a280",
   "metadata": {},
   "source": [
    "# datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5203c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lib_name = 'datatable'\n",
    "stats = []\n",
    "\n",
    "for i in range(num_ran):\n",
    "    stats_inner = {}\n",
    "    start = time.time()\n",
    "    df_1 = dt.fread(file_1)\n",
    "    print(f'loading csv with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['loading_1'] = (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    df_2 = dt.fread(file_2)\n",
    "    print(f'loading csv with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['loading_2'] = (time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    df_2 = dt.rbind(df_1, df_2)\n",
    "    print(f'vertically concat csv with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['concat'] = (time.time() - start)\n",
    "    \n",
    "    df_3 = df_1[:,0:10]\n",
    "    start = time.time()\n",
    "    df_3[:,dt.sum(f[:]), by('text_id')]\n",
    "    print(f'groupby and sum csv with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['groupby'] = (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    df_1['0_2'] = f[1] * 2 +1\n",
    "    print(f'simple column calculation with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['column calculation'] = (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    df_1[f.text_id == '9999_ID',:]\n",
    "    print(f'filtering with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['filtering'] = (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    df_1[f.text_id == '9999_ID','text_id'] = 'found it'\n",
    "    print(f'filtering and update value with {lib_name} took: {time.time()-start} seconds.')\n",
    "    stats_inner['filtering & updating'] = (time.time() - start)\n",
    "    \n",
    "    stats_inner['merge'] = 0\n",
    "    stats.append(stats_inner)\n",
    "\n",
    "print([k for k in sorted(stats[0].keys())])\n",
    "datatable_stats = [round((stats[0][k] + stats[1][k])/2,5) for k in sorted(stats[0].keys())]\n",
    "print(datatable_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506853eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time test('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96594053",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time test('modin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pl.read_csv(file_1)\n",
    "df2 = pl.read_csv(file_2)\n",
    "df3 = pl.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ec2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f737267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df1.join(df2, on ='unique_id_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a810e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c1f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc8644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.groupby('text_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73354d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
