{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e39a54-412d-4c74-9927-4d0d1ce622dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce13d4-31d9-403b-a3a5-c7ffee05f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_keys=dotenv_values()\n",
    "os.environ['OPENAI_API_KEY'] = dotenv_values()['openai_api_key'] #set environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f07628-70f8-41f7-9f1d-d49a404cb2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(r\"E:\\PythonInOffice\\langchain_egs\\00_getting_started\\sd+midjourney_wiki.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4dc1b4-2893-4a7d-81a6-8062d6934d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97744adb-8539-4907-a5a8-330933c2896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fb240-7cd1-49a0-9ca5-a7b692e773c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.encode(docs[0].page_content)\n",
    "len(encoding.encode(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02e3fe-9d95-48c1-b17e-aefc984b3b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de94ed1-944c-4b44-91d6-67d82312c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 4000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1992fc-7bc3-4b35-b78d-8475b01f5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4cb12-cf4d-4736-a165-d7d56668b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a8268-2d8e-4c7a-a6e3-eec97defda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49746411-61b2-49e5-90b7-462c2b23e63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4244e652-4ae3-4d9d-9b6f-e2a50723553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
    "stuff_chain = load_summarize_chain(llm, chain_type='stuff', verbose=True)\n",
    "\n",
    "#will show an error\n",
    "stuff_chain.run(docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa54f6-4d99-4947-ab89-dd4bdaa007bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "map_reduce_chain  = load_summarize_chain(llm, chain_type='map_reduce', verbose=True)\n",
    "\n",
    "map_reduce_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3a5c2-af26-4565-853e-d9bc4035b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_chain = load_summarize_chain(llm, chain_type='refine', verbose=True)\n",
    "refine_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5357cb-dccc-43e1-8776-a7b07cc071b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "llm = OpenAI(temperature=0)\n",
    "map_rerank_chain = load_qa_chain(llm, chain_type='map_rerank', verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc4d75-8403-49f5-b9b9-856a7de7d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_rerank_chain({'input_documents': docs,\n",
    "                 'question': \"what's the main feature of midjourney?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a1ada-a16f-4e2f-a423-6e36e50b6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import openai\n",
    "import os\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "api_keys=dotenv_values()\n",
    "os.environ['OPENAI_API_KEY'] = dotenv_values()['openai_api_key'] #set environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e919642-d7e3-4756-9815-e68a16c473e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\") # gpt-4, gpt-3.5-turbo, text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e906311-fc67-451e-bc21-f76b24d2065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.encode(\"let's count tokens!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ac127-a76a-499a-9614-69dec59d0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_num = len(encoding.encode(\"let's learn about tokens!\"))\n",
    "print(f'number of token is: {token_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2e831-238d-4ab0-bfd8-b5b22cee4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "#encode\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\") # gpt-4, gpt-3.5-turbo, text-embedding-ada-002\n",
    "encoding.encode(\"guess how many tokens are in this sentence?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615c8f3-2db3-4117-8964-a7a93a94cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_num = len(encoding.encode(\"guess how many tokens are in this sentence?\"))\n",
    "print(f'number of token is: {token_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fbdd0-9e51-4615-8ba8-118f48a18925",
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn token into text\n",
    "encoding.decode([52851, 1268, 1690, 11460, 527, 304, 420, 11914, 30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-venv",
   "language": "python",
   "name": "langchain-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
